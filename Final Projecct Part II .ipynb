{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ballwang\\anaconda3.3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import difflib\n",
    "import spacy\n",
    "import scipy\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from nltk.stem.porter import *\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ballwang\\anaconda3.3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load the original data\n",
    "full_data = pd.read_csv(\"Full data.csv\")[[\"product_id\", \"description\", \"brand_category\"]].fillna('UNKNOWN_TOKEN')\n",
    "combination = pd.read_csv(\"outfit_combinations.csv\", encoding = 'utf-8').fillna('UNKNOWN_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_data.drop(full_data[(full_data['description'] == 'UNKNOWN_TOKEN')].index, inplace = True)\n",
    "# replace 'accessory2' and 'accessory3' to 'accessory'\n",
    "combination.outfit_item_type[(combination.outfit_item_type == 'accessory1') | (combination.outfit_item_type == 'accessory2') | (combination.outfit_item_type == 'accessory3' )] = 'accessory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DSRPSZTDW2PGK1YWYXJGKZZ0</td>\n",
       "      <td>Vintage Fitness leather sneakers with logo pri...</td>\n",
       "      <td>TheMensStore/Shoes/Sneakers/LowTop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DPGV8TGRAB993PF7Z3YWG2VR</td>\n",
       "      <td>A Timeless Leather Belt Crafted From Smooth Co...</td>\n",
       "      <td>Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DSR8G3F7DBRTMP8THF97XSQ2</td>\n",
       "      <td>Pretty ruffle sleeves and trim elevate essenti...</td>\n",
       "      <td>JustKids/Girls214/Girls/SwimwearCoverups,JustK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DSR8G5GP519DEDCSKBMWQVK5</td>\n",
       "      <td>Versatile convertible gown with elephant applique</td>\n",
       "      <td>JustKids/Baby024months/InfantGirls/FootiesRompers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01DSR8GF05981EG88DHBETKXMR</td>\n",
       "      <td>From the Savage Love Collection. Fingerless kn...</td>\n",
       "      <td>JewelryAccessories/Accessories/Gloves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42368</th>\n",
       "      <td>01DT5110V2ME7BY3JPCAJ91QRW</td>\n",
       "      <td>Mélange beige and cream wool Button fastenings...</td>\n",
       "      <td>Clothing / Coats / Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42369</th>\n",
       "      <td>01DV6M2FXMPW9RSZWSXW1EK75W</td>\n",
       "      <td>Cream georgette Ties at neck, concealed hook f...</td>\n",
       "      <td>Clothing / Tops / Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42370</th>\n",
       "      <td>01DV71D0XMBM4VVJK54F2HD3ZG</td>\n",
       "      <td>Sand cotton-corduroy Concealed hook and zip fa...</td>\n",
       "      <td>Clothing / Skirts / Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42371</th>\n",
       "      <td>01DV72R28K2A1AN5G167S6QRWF</td>\n",
       "      <td>Although mom jeans and boyfriend jeans are all...</td>\n",
       "      <td>women:CLOTHING:JEANS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42372</th>\n",
       "      <td>01DSNZTZNH0NG60JWJ07KPQ465</td>\n",
       "      <td>ONLY AT SAKS. Ultra-sporty nylon track jacket ...</td>\n",
       "      <td>TheMensStore/Apparel/Outerwear/LightweightJackets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35187 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       product_id  \\\n",
       "0      01DSRPSZTDW2PGK1YWYXJGKZZ0   \n",
       "2      01DPGV8TGRAB993PF7Z3YWG2VR   \n",
       "3      01DSR8G3F7DBRTMP8THF97XSQ2   \n",
       "4      01DSR8G5GP519DEDCSKBMWQVK5   \n",
       "5      01DSR8GF05981EG88DHBETKXMR   \n",
       "...                           ...   \n",
       "42368  01DT5110V2ME7BY3JPCAJ91QRW   \n",
       "42369  01DV6M2FXMPW9RSZWSXW1EK75W   \n",
       "42370  01DV71D0XMBM4VVJK54F2HD3ZG   \n",
       "42371  01DV72R28K2A1AN5G167S6QRWF   \n",
       "42372  01DSNZTZNH0NG60JWJ07KPQ465   \n",
       "\n",
       "                                             description  \\\n",
       "0      Vintage Fitness leather sneakers with logo pri...   \n",
       "2      A Timeless Leather Belt Crafted From Smooth Co...   \n",
       "3      Pretty ruffle sleeves and trim elevate essenti...   \n",
       "4      Versatile convertible gown with elephant applique   \n",
       "5      From the Savage Love Collection. Fingerless kn...   \n",
       "...                                                  ...   \n",
       "42368  Mélange beige and cream wool Button fastenings...   \n",
       "42369  Cream georgette Ties at neck, concealed hook f...   \n",
       "42370  Sand cotton-corduroy Concealed hook and zip fa...   \n",
       "42371  Although mom jeans and boyfriend jeans are all...   \n",
       "42372  ONLY AT SAKS. Ultra-sporty nylon track jacket ...   \n",
       "\n",
       "                                          brand_category  \n",
       "0                     TheMensStore/Shoes/Sneakers/LowTop  \n",
       "2                                            Accessories  \n",
       "3      JustKids/Girls214/Girls/SwimwearCoverups,JustK...  \n",
       "4      JustKids/Baby024months/InfantGirls/FootiesRompers  \n",
       "5                  JewelryAccessories/Accessories/Gloves  \n",
       "...                                                  ...  \n",
       "42368                            Clothing / Coats / Long  \n",
       "42369                          Clothing / Tops / Blouses  \n",
       "42370                           Clothing / Skirts / Mini  \n",
       "42371                               women:CLOTHING:JEANS  \n",
       "42372  TheMensStore/Apparel/Outerwear/LightweightJackets  \n",
       "\n",
       "[35187 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.drop_duplicates(inplace = True)\n",
    "full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_data.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_cleaning(description):\n",
    "    \"\"\"\n",
    "    Obtain a TFIDF vector for a given product\n",
    "    \n",
    "    Parameters:\n",
    "    arg1(string): The description of the product\n",
    "    arg2(string): The details of the product\n",
    "    arg3(string): The full_name of the product\n",
    "    arg4(string): IDF score calculated from the training data\n",
    "    \n",
    "    Return the TFIDF vector\n",
    "    \"\"\"\n",
    "    ## Function to remove special characters\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    ## Function to convert nltk tag to wordnet tag\n",
    "    def nltk2wn_tag(nltk_tag):\n",
    "        if nltk_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif nltk_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif nltk_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif nltk_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return None\n",
    "    ## Function to lemmatize\n",
    "    def lemmatize_sentence(sentence):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "        wn_tagged = map(lambda x :(x[0], nltk2wn_tag(x[1])), nltk_tagged)\n",
    "        res_words = []\n",
    "        for word, tag in wn_tagged:\n",
    "            if tag is None:\n",
    "                res_words.append(word)\n",
    "            else:\n",
    "                res_words.append(lemmatizer.lemmatize(word,tag))\n",
    "        return \" \".join(res_words)\n",
    "    ## Difine a function to calculate the term frequency array\n",
    "    def all_list(arr):\n",
    "        result = {}\n",
    "        for i in set(arr):\n",
    "            result[i] = arr.count(i)\n",
    "        return result\n",
    "    \n",
    "    ## Define different stopwords lists for three different inputs\n",
    "    stopword = set(stopwords.words('english'))\n",
    "    stopword_des = stopwords.words('english') + ['.' , '', ]\n",
    "    \n",
    "    # Regax cleaning for description\n",
    "    des = re.sub(r'[^\\w+0-9%.]', ' ', description, flags = re.IGNORECASE)\n",
    "    ## Replace all numbers with % with text description (HIGH/MEDIAN/LOW)\n",
    "    perc = re.findall(r'(\\d+)(?:%)\\s', des)\n",
    "    temp_content = \"\"\n",
    "    temp = []\n",
    "    if perc != []:\n",
    "        for i in perc:\n",
    "            if int(i) >= 80:\n",
    "                temp_content = temp_content + \"HIGH\"\n",
    "            elif int(i) >= 40:\n",
    "                temp_content = temp_content + \"MEDIAN\"\n",
    "            else:\n",
    "                temp_content = temp_content + \"LOW\"\n",
    "            temp.append(temp_content)\n",
    "            temp_content = \"\"\n",
    "    des = re.sub(r\"(\\d+)(?:%)\\s(\\w+)\", \"MATERIAL\", des, flags = re.IGNORECASE)\n",
    "    flag = 0\n",
    "    temp_list = []\n",
    "    for word in des.split(\" \"):\n",
    "        if word == \"MATERIAL\":\n",
    "            temp_list.append(\"{}_MATERIAL\".format(temp[flag]))\n",
    "            flag += 1\n",
    "        else:\n",
    "            temp_list.append(word)\n",
    "    temp_des = \" \".join(temp_list)\n",
    "    des = re.sub(r\"((\\d+\\.\\d+)|(\\d+))\", \"NUMERICAL_VALUE\", temp_des, flags = re.IGNORECASE)\n",
    "    ## Remove stopwords, unnecessary punctuations and lower cases\n",
    "    updated_des = []\n",
    "    temp_des = []\n",
    "    line = re.findall(r'\\b[a-zA-Z0-9_]{2,}\\b',des)\n",
    "    for word in line:\n",
    "        if word.lower() in stopword_des:\n",
    "            continue\n",
    "        temp_des.append(word.lower())\n",
    "    updated_des = \" \".join(temp_des)\n",
    "    ## Lemmatize the description\n",
    "    updated_des = lemmatize_sentence(updated_des)\n",
    "    \n",
    "    return(updated_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_clean = []\n",
    "for description in full_data['description']:\n",
    "    description_clean.append(regex_cleaning(description))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sentence Vector of each Description in Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [word_tokenize(sentence) for sentence in description_clean]\n",
    "model = Word2Vec(docs, min_count = 1, window = 5, size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_vector = []\n",
    "for item in description_clean:\n",
    "    temp_vector = np.zeros((1,500))\n",
    "    n = 0\n",
    "    for word in item.split(\" \"):\n",
    "        if word in model.wv.vocab:\n",
    "            temp_vector += model.wv.get_vector(word)\n",
    "        else:\n",
    "            temp_vector += np.random.normal(size=500)\n",
    "        n += 1\n",
    "    product_vector.append(temp_vector/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzywozzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regax for 5 categories, cleaning the full data\n",
    "top = r\"\\b(top|tops|shirt|shirts|coat|coats|jacket|jackets|blouse|blouses|blazer|sweaters|sweater|knitwear|bodysuits|polos)\\b\"\n",
    "bottom = r\"\\b(bottom|trousers|pant|pants|jeans|shorts|skirts|leggings|legging|camisoles and chemises)\\b\"\n",
    "one_piece = r\"\\b(one-piece|jumpsuits|rompers|dungarees|dresses|pajamas_intimates|pajamas)\\b\"\n",
    "shoe = r\"\\b(shoe|shoes|sneakers|cleats|high heels|boot|boots|mukluks|flip-flops|suits\\\n",
    "        galoshes|clogs|loafers|pumps|moccasins|sandals|skates|waders|zoris|mule)\\b\"\n",
    "accessory = r\"\\b(accessory|accessories|sunglasses|bag|bags|handbag|handbags|scarf|scarfs|scarves|belt|belts|necklaces|jewelry|brooch|hat|hats|cap|caps)\\b\"\n",
    "useless_regax = \"homehitech|swimwear|coverups|saksbeautyplace|toys|justkids|themensstore\"\n",
    "\n",
    "full = full_data.copy()\n",
    "\n",
    "full[\"brand_category\"] = full[\"brand_category\"].apply(lambda x: x.lower())\n",
    "full[\"description\"] = full[\"description\"].apply(lambda x: str(x))\n",
    "full[\"description\"] = full[\"description\"].apply(lambda x: x.lower())\n",
    "\n",
    "full[\"useless_regax\"] = full[\"brand_category\"].str.findall(useless_regax) + full[\"description\"].str.findall(useless_regax)\n",
    "full[\"useless_regax\"] = full[\"useless_regax\"].apply(lambda x: \"yes\" if x != [] else [])\n",
    "\n",
    "full = full[full[\"useless_regax\"] != \"yes\"]\n",
    "\n",
    "full[\"top_result\"] = full[\"brand_category\"].str.findall(top)\n",
    "full[\"top_result\"] = full[\"top_result\"].apply(lambda x: [\"top\"] if x != [] else [])\n",
    "\n",
    "full[\"bottom_result\"] = full[\"brand_category\"].str.findall(bottom)\n",
    "full[\"bottom_result\"] = full[\"bottom_result\"].apply(lambda x: [\"bottom\"] if x != [] else [])\n",
    "\n",
    "full[\"one_piece_result\"] = full[\"brand_category\"].str.findall(one_piece)\n",
    "full[\"one_piece_result\"] = full[\"one_piece_result\"].apply(lambda x: [\"one piece\"] if x != [] else [])\n",
    "\n",
    "full[\"shoe_result\"] = full[\"brand_category\"].str.findall(shoe)\n",
    "full[\"shoe_result\"] = full[\"shoe_result\"].apply(lambda x: [\"shoe\"] if x != [] else [])\n",
    "\n",
    "full[\"accessory_result\"] = full[\"brand_category\"].str.findall(accessory)\n",
    "full[\"accessory_result\"] = full[\"accessory_result\"].apply(lambda x: [\"accessory\"] if x != [] else [])\n",
    "\n",
    "full[\"result\"] = full[\"top_result\"] + full[\"bottom_result\"] + full[\"one_piece_result\"] + full[\"shoe_result\"] + full[\"accessory_result\"]\n",
    "full[\"result\"] = full[\"result\"].apply(lambda x: \"{}\".format(x) if x != [] else 0)\n",
    "    \n",
    "final = full[full[\"result\"] != 0]\n",
    "final = final[final[\"result\"] != \"['bottom', 'one piece']\"]\n",
    "final = final[final[\"result\"] != \"['top', 'shoe']\"]\n",
    "final = final[final[\"result\"] != \"['top', 'accessory']\"]\n",
    "final = final[final[\"description\"] != \"nan\"]\n",
    "final = final[[\"product_id\", \"description\", \"brand_category\", \"result\"]].reset_index(drop = True)\n",
    "final[\"result\"] = final[\"result\"].apply(lambda x: x[2:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create function to output the desire outfit combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the input as two different scenarios. \n",
    "\n",
    "If input is an ID\n",
    "1. compare which product ID is most close to the product ID in combination data using Fuzzywuzzy\n",
    "2. If Fuzzywuzzy score greater than 80, we would take the first product id with one of its outfit id as our reference\n",
    "    2.1. output the outfit combination corresponding to that outfit it\n",
    "3. If Fuzzywuzzy score less than 80\n",
    "    3.1. turn to the full data to find out the highest fuzzywuzzy score with same type as input\n",
    "    3.2. save that description of that product with same item type and pass this description and input type to our second scenarios\n",
    "    \n",
    "If input is a description\n",
    "1. compare the input description with all the product description using cosine similiarity\n",
    "2. find the highest scores (< 0.9999) and find the corresponding outfit id (random one)\n",
    "3. output the outfit combination result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim_recommend(full_data, product_vector):\n",
    "    \"\"\"\n",
    "    Please enter a product description with valid format,  \" \"'text', 'text' \", without parentheses\n",
    "    this function will recommend suitable apparel combination based on the input styling.\n",
    "    \"\"\"\n",
    "    item = pd.Series(input('please input your product: '))\n",
    "    item = item.str.findall(r'\\b\\w+\\b')\n",
    "    item_type = item[0][0]\n",
    "    item_des = \" \".join(item[0][1:])\n",
    "    temp_wordvec = np.zeros((1,500))\n",
    "    input_vector = []\n",
    "    index = 0\n",
    "    \n",
    "    if len(item_des.split(' ')) == 1:\n",
    "        combination['score'] = combination['product_id'].apply(lambda x: fuzz.token_sort_ratio(x, item_des))\n",
    "        combination.sort_values(by = \"score\", ascending = False, inplace = True)\n",
    "        combination.reset_index(drop = True, inplace = True)\n",
    "        if combination[\"score\"][0] >= 80:\n",
    "            outfit_id = combination[combination[\"score\"] == combination[\"score\"][0]][\"outfit_id\"][0]\n",
    "            recommendation = combination[combination[\"outfit_id\"] == outfit_id][[\"outfit_id\", \"product_full_name\", \"outfit_item_type\"]]\n",
    "            for outfittype in recommendation[\"outfit_item_type\"]:\n",
    "                recommendation = combination[combination[\"outfit_id\"] == outfit_id][[\"outfit_id\", \"product_full_name\", \"outfit_item_type\"]]\n",
    "                print(\"{} :{} ({})\".format(outfittype, recommendation[recommendation[\"outfit_item_type\"] == outfittype][\"product_full_name\"].values, \\\n",
    "                                       recommendation[recommendation[\"outfit_item_type\"] == outfittype][\"outfit_id\"].values, ))\n",
    "        else:\n",
    "            temp_df = final[final[\"result\"] == item_type]\n",
    "            temp_df[\"score\"] = temp_df[\"product_id\"].apply(lambda x: fuzz.token_sort_ratio(x, item_des))\n",
    "            temp_df.sort_values(by = \"score\", ascending = False, inplace = True)\n",
    "            temp_df.reset_index(drop = True, inplace = True)\n",
    "            item_des = temp_df[temp_df[\"score\"] == temp_df[\"score\"][0]][\"description\"][0]\n",
    "            \n",
    "    # when there is an input, transfer them into word2vec based on the exisiting word2vec rules (average)\n",
    "    for word in regex_cleaning(item_des).split(\" \"):\n",
    "        if word in model.wv.vocab:\n",
    "            temp_wordvec += model.wv.get_vector(word)\n",
    "        else:\n",
    "            temp_wordvec += np.random.normal(size = 500)\n",
    "        index += 1\n",
    "    input_vector.append(temp_wordvec / index)\n",
    "    \n",
    "    # calculate cos similiarity score\n",
    "    cos_sim = []\n",
    "    for sentence in range(len(full_data)):\n",
    "        detail = product_vector[sentence]\n",
    "        similarity = 1 - scipy.spatial.distance.cosine(input_vector, detail)\n",
    "        cos_sim.append(similarity)\n",
    "    cos_sim = pd.DataFrame(cos_sim, index = full_data.index, columns = ['score'])\n",
    "    cos_sim['product_id'] = full_data['product_id']\n",
    "    \n",
    "    # filter out the most closed similar one\n",
    "    cos_sim = cos_sim[cos_sim.score < 0.99999]\n",
    "    # sort based on the score\n",
    "    cos_sim = cos_sim.sort_values(by = ['score'], ascending = False)  \n",
    "    \n",
    "    # only select outfit_id(index) which satisfy the highest cos sim scores, has more than 3 outfit combination, and has same type as input\n",
    "    fit_id = 0\n",
    "    for index in cos_sim.product_id:\n",
    "        if len(combination.outfit_id[combination.product_id == index]) > 0:\n",
    "            if len(combination[combination.outfit_id == combination.outfit_id[combination.product_id == index].iloc[0]]) >= 3 and combination.outfit_item_type[combination.product_id == index].iloc[0] == item_type:\n",
    "                fit_id = combination.outfit_id[combination.product_id == index].iloc[0]\n",
    "                break\n",
    "    comb = combination[combination.outfit_id == fit_id]\n",
    "    final_comb = pd.DataFrame()\n",
    "    \n",
    "    # randomly select one of the duplicate accessory\n",
    "    for type in comb.outfit_item_type.unique():\n",
    "        temp = comb[comb.outfit_item_type==type]\n",
    "        if temp.shape[0]==1:\n",
    "            final_comb = final_comb.append(temp,ignore_index=True,sort=False)\n",
    "        else:\n",
    "            temp = temp.iloc[0,:]\n",
    "            final_comb = final_comb.append(temp,ignore_index=True,sort=False)\n",
    "    for index in final_comb.index:\n",
    "        print(final_comb.loc[index, 'outfit_item_type'], ':', final_comb.loc[index, 'product_full_name'], '(', final_comb.loc[index, 'outfit_id'],')')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run through all the Jupyter Notebook and function 'cos_sim_recommend' with two prepared input, full_data and product_vector\n",
    "\n",
    "The Notebook will process two input data, 'Full data.csv' and 'outfit_combinations.csv'\n",
    "\n",
    "This function will output a set of recommended apparel combination based on the input styling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_recommend(full_data, product_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
